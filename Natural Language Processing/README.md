# Awesome Natural Language Processing
I share information related to the NLP what I interested in.

- modified : 2022-09-15


## Natural Language Processing 

### Models

- Word2Vec (2013): [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)

- Transformer (2017) : [Attention is all you need](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf?ref=https://githubhelp.com)

- BERT (2018): [Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)

- GPT (2018): [Improving Language Understandingby Generative Pre-Training](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf)

- GPT-2 (2019): [Language Models are Unsupervised Multitask Learners](https://life-extension.github.io/2020/05/27/GPT%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/language-models.pdf)

- XLM (2019): [Cross-lingual Language Model Pretraining](https://arxiv.org/pdf/1901.07291.pdf)

- BERT-E2E-ABSA (2019): [Exploiting BERT for End-to-End Aspect-based Sentiment Analysis](https://arxiv.org/pdf/1910.00883.pdf)

- RoBERTa (2019): [A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/pdf/1907.11692.pdf)

- CTRL (2019): [CTRL: A Conditional Transformer Language Model for Controllable Generation](https://arxiv.org/pdf/1909.05858.pdf)

- ALBERT (2019): [Albert: A Lite Bert for Self-supervised Learning of Language Representations](https://arxiv.org/pdf/1909.11942.pdf)

- DistillBERT (2019): [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/pdf/1910.01108.pdf)

- GPT-3 (2020): [Language Models are Few-Shot Learners](https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)

- ELECTRA (2020): [Electra: Pre-training text encoders as discriminators rather than generators](https://arxiv.org/pdf/2003.10555.pdf)

- BigBird (2020): [Big bird: Transformers for Longer Sequences](https://proceedings.neurips.cc/paper/2020/file/c8512d142a2d849725f31a9a7a361ab9-Paper.pdf)

- Reformer (2020): [Reformer: The efficient transformer](https://arxiv.org/pdf/2001.04451.pdf)


### Survey

- [A Survey on Aspect-Based Sentiment Analysis: Tasks, Methods, and Challenges](https://arxiv.org/pdf/2203.01054.pdf)

- [AMMUS: A Survey of Transformer-based Pretrained Models in Natural Language Processing](https://arxiv.org/pdf/2108.05542.pdf)
